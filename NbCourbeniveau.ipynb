{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd as autograd \n",
    "from autograd import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelques Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda X : (X[1])**2 +(X[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=lambda X : np.exp(-X[0]**2-X[1]**2)\n",
    "g2=lambda X : np.exp( -(X[0]-1)**2-(X[1]-1)**2)\n",
    "\n",
    "def f(X):\n",
    "    return 2*(np.exp(-X[0]**2-X[1]**2)-np.exp( -(X[0]-1)**2-(X[1]-1)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projet Maths info\n",
    "## Courbes de niveau \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Déceler une amorce\n",
    "On souhaite déterminer une solution de l'équation $f(x,y)=c$ sur le bord gauche de la surface $[0,1]^2$ \n",
    "### Méthode de Newton à 1D pour des fonctions de 1 variable\n",
    "- Soit $f: [0,1]² \\to \\mathbb{R}$ on considère $f \\in C^1$, Soit $x=0$  considérons $ g:[0,1] \\to \\mathbb{R} , y \\mapsto f(x,y)$ la fonction à une seule variable.\n",
    "- Résolvons l'équation $g(y)=c$ sur $[0,1]$ :\n",
    "    - Pour ce faire utilisons la méthode de Newton qui nous dit, en supposant que la fonction est différentiable et que sa dérivéee ne s'annule pas sur $[0,1]$,  que la suite $(_k)_\\mathbb{N}$ définie par $ y_{k+1}=y_{k} -\\frac{g(x_k)}{g'(x_{k})}$ est convrgente et de limite y solution de l'équation $g(y)=c$\n",
    "- On implémente ainsi l'algorithme de résolution d'équation en construisant itérativement la suite.\n",
    "- On considère la limite atteinte lorsque la distance entre deux $x_k$ successifs est plus petit qu'un certain $\\epsilon$ fixé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seed_newt(g,c=0,eps=2**(-26)):\n",
    "    if (g([0,1])-c)*(g([0,0])-c)>0:\n",
    "        return None\n",
    "    else : \n",
    "        gradg = autograd.grad(g)\n",
    "        x_0 = 5\n",
    "        x = x_0 -(g(np.array([0.,x_0]))-c)/gradg(np.array([0.,x_0]))[1]\n",
    "        while abs(x-x_0) > eps:\n",
    "            x_0 = x\n",
    "            x = x_0-(g(np.array([0,x_0]))-c)/gradg(np.array([0,x_0]))[1]\n",
    "        return [0,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_seed_newt(g,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche Dichotomique \n",
    "\n",
    "- Mais la méthode de Newton paye sa grande rapidité de convergence par une faible stabilité, en effet il faut trouver une amorce qui est assez proche du point de convergence. Sinon la suite des ($y_k$) diverge \n",
    "- De plus cette méthode n'est pas appliquable si à un moment on passe par un point où la dérivée s'annule\n",
    "\n",
    "**On préferera donc dans la suite la méthode de recherche dichotomique qui un peu moins rapide mais qui converge à coup sur vers une solution quand il en existe une.** L'expérience a montré que plusieurs fois l'une des initialisation des fonctions `find_seed_X` se faisait en un point où la dérivée était nulle, ce qui rendait impossible la méthode de Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seed_dicho (g,c=0,limx=[0.,1.],limy=[0.,1.],eps=2**(-26)):\n",
    "    if (g([limx[0],limy[0]])-c)*(g([limx[0],limy[1]])-c)<=0 :\n",
    "        a,b=limy[0],limy[1]\n",
    "        if g([limx[0],a])>g([limx[0],b]):\n",
    "            a,b=b,a\n",
    "        while abs(b-a)>eps:\n",
    "            d=(a+b)/2\n",
    "            if (g([limx[0],d])-c)>0:\n",
    "                b=d\n",
    "            else:\n",
    "                a=d\n",
    "        return [limx[0],d]\n",
    "    else :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "find_seed_dicho(g,1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracé de lignes de niveau\n",
    "## Construction par cheminement\n",
    "\n",
    "On utlise premièrement la propriété qui énonce que une certaine ligne de niveau est en tout point perpendiculaire au gradient.\n",
    "\n",
    "- En effet soit {$\\mathbb{R},(x(t),y(t))$} l'arc paramétré suivant la ligne de niveau tel quel $\\forall t \\in \\mathbb{R}, f(x(t),y(t))=c$\n",
    "    - Soit $x_0$ un point, on a alors d'après la régle de dérivation selon un arc $\\dfrac{df(x(t),y(t))}{dt}=\\nabla(f(x_0)).x'(t)=0$ D'où le gradient est Orthogonal à la tangente à la ligne de niveau en tous points.\n",
    "\n",
    "\n",
    "\n",
    "- On part donc d'une amorce que l'on calcule avec la fonction  `find_seed` et on se déplace d'une distance delta selon la direction perpendiculaire au gradient en ce point. L'erreur s'accumule à chaque itération, mais l'implémentation est relativement aisée. Et une division de la zone de recherche en cellule permet d'éviter d'accumuler cette erreur sur une trop longue \"distance\"\n",
    "\n",
    "\n",
    "- Cf. $Méthode\\space d'Euler$ qui est d'ordre 1 \n",
    "\n",
    "\n",
    "- On détermine $\\begin{pmatrix} x_{0} \\\\ y_{0}\\end{pmatrix}$ à l'aide de la fonction `find_seed`\n",
    "\n",
    "- En considérant le Gradient $\\overrightarrow{\\text{grad}}\\,f(\\text{M})= \\begin{pmatrix} \n",
    "\\dfrac{\\partial f}{\\partial x} \\\\ \n",
    " \\dfrac{\\partial f}{\\partial y}\n",
    " \\end{pmatrix}$ On en déduit que le vecteur directeur de la tangente à la ligne de niveau est : $\\overrightarrow{V_\\parallel}(\\text{M})=\\begin{pmatrix} \n",
    "\\dfrac{\\partial f}{\\partial y} \\\\ \n",
    "-\\dfrac{\\partial f}{\\partial x}\n",
    " \\end{pmatrix}$\n",
    "- On calcule les points de la courbe de niveau comme étant les points de la suite de formule de réccurence  : $M_{k+1}=\\begin{pmatrix} x_{k+1} \\\\ y_{k+1}\\end{pmatrix} = \\begin{pmatrix} x_{k} \\\\ y_{k}\\end{pmatrix} + \\dfrac{\\delta}{||\\overrightarrow{\\text{grad}}\\,f(\\text{M})||}.\\begin{pmatrix}\\dfrac{\\partial f}{\\partial y} \\\\ -\\dfrac{\\partial f}{\\partial x} \\end{pmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_contour (g,c=0,delta=0.01):\n",
    "    abscisses,ordonnées =[],[]\n",
    "    position=np.array(find_seed_newt(g,c))\n",
    "    gradg=autograd.grad(g)\n",
    "    abscisses.append(position[0])\n",
    "    ordonnées.append(position[1])\n",
    "    def test (position) :\n",
    "        return 0<=position[0]<=1 and 0<=position[1]<=1\n",
    "    \n",
    "    while test(position) :\n",
    "        gradX = gradg(position)\n",
    "        norme = np.sqrt(gradX[1]**2+gradX[0]**2)\n",
    "        vect = np.array([gradX[1]/norme,-1*gradX[0]/norme])\n",
    "        position = position + vect*delta\n",
    "        abscisses.append(position[0])\n",
    "        ordonnées.append(position[1])\n",
    "    return abscisses,ordonnées \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de tracé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=simple_contour(g,1,0.01)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(c[0],c[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erreur accumulée\n",
    "La méthode d'Euler est une méthode d'ordre 1 d'où la croissance linéaire de l'erreur avec les itérations. Un $\\delta$  très petit minimise l'erreur sur un grand nombre d'itération. De plus on tachera au minimum de limiter les itérations de cette méthode en restreignant la zone d'étude afin d'éviter à l'erreur de s'accumuler. On peut tracer l'erreur au fur et à mesure de l'itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=simple_contour(g,1,0.5)\n",
    "b=simple_contour(g,1,0.1)\n",
    "c=simple_contour(g,1,0.01)\n",
    "plt.close()\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\" Tracé de la ligne de niveau en fonction de $\\delta$\")\n",
    "plt.plot(a[0],a[1],label='$\\delta$=0.5')\n",
    "plt.plot(b[0],b[1],label='$\\delta$=0.1')\n",
    "plt.plot(c[0],c[1],label='$\\delta$=0.01')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot((np.array(a[0])**2+np.array(a[1])**2)-1,label='$\\delta$=0.5')\n",
    "plt.plot((np.array(b[0])**2+np.array(b[1])**2)-1,label='$\\delta$=0.1')\n",
    "plt.plot((np.array(c[0])**2+np.array(c[1])**2)-1,label='$\\delta$=0.01')\n",
    "plt.title(\"Tracé de l'erreur en fonction du nombre d'itération\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\Rightarrow$ on ne peut accepter une aussi grosse erreur\n",
    "\n",
    "- A priori pour une observation graphique, cela ne poserait pas trop de problème. Mais en fait, il faut être plus précis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fonction de tracé\n",
    "## Recherche d'amorce évoluée\n",
    "On réecrit la fonction `find_seed_dicho` pour la rendre capable d'effectuer le test sur les quetres coté de la zone. On ne priorise pas une amorce plutôt qu'une autre car dans le cadre de notre méthode, il est possible que l'orientation du Gradient fasse que la ligne de niveau soit dirigéee vers un point en dehors de la cellule\n",
    "- On définit 4 fonctions de type `find_seed_dicho` mais qui sont écrites pour chacun des bords d'une cellule, elle prend en argument des informations supplémentaires qui permettront à la dichotomie de s'initialiser n'importe où dans la zone de recherche.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seed_D (g,c=0,limx=[0.,1.],limy=[0.,1.],eps=2**(-26)):\n",
    "    if (g([limx[1],limy[0]])-c)*(g([limx[0],limy[0]])-c)<0:\n",
    "        a,b=limx[0],limx[1]\n",
    "        if g([a,limy[0]])>g([b,limy[0]]):\n",
    "            a,b=b,a\n",
    "        while abs(b-a)>eps:\n",
    "            d=(a+b)/2\n",
    "            if (g([d,limy[0]])-c)>0:\n",
    "                b=d\n",
    "            else:\n",
    "                a=d\n",
    "        return [d,limy[0]]\n",
    "    else :\n",
    "        return None\n",
    "def find_seed_L (g,c=0,limx=[0.,1.],limy=[0.,1.],eps=2**(-26)):\n",
    "    if (g([limx[0],limy[0]])-c)*(g([limx[0],limy[1]])-c)<=0 :\n",
    "        a,b=limy[0],limy[1]\n",
    "        if g([limx[0],a])>g([limx[0],b]):\n",
    "            a,b=b,a\n",
    "        while abs(b-a)>eps:\n",
    "            d=(a+b)/2\n",
    "            if (g([limx[0],d])-c)>0:\n",
    "                b=d\n",
    "            else:\n",
    "                a=d\n",
    "        return [limx[0],d]\n",
    "    else :\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_seed_U (g,c=0,limx=[0.,1.],limy=[0.,1.],eps=2**(-26)):\n",
    "    if (g([limx[0],limy[1]])-c)*(g([limx[1],limy[1]])-c)<=0 :\n",
    "        a,b=limx[0],limx[1]\n",
    "        if g([a,limy[1]])>g([b,limy[1]]):\n",
    "            a,b=b,a\n",
    "        while abs(b-a)>eps:\n",
    "            d=(a+b)/2\n",
    "            if (g([d,limy[1]])-c)>0:\n",
    "                b=d\n",
    "            else:\n",
    "                a=d\n",
    "        return [d,limy[1]]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def find_seed_R(g,c=0,limx=[0.,1.],limy=[0.,1.],eps=2**(-26)):\n",
    "    if  (g([limx[1],limy[1]])-c)*(g([limx[1],limy[0]])-c)<=0 :\n",
    "        a,b=limy[0],limy[1]\n",
    "        if g([limx[1],a])>g([limx[1],b]):\n",
    "            a,b=b,a\n",
    "        while abs(b-a)>eps:\n",
    "            d=(a+b)/2\n",
    "            if (g([limx[1],d])-c)>0:\n",
    "                b=d\n",
    "            else:\n",
    "                a=d\n",
    "        return [limx[1],d]\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction évoluée\n",
    "- Dans cette nouvelle fonction `simple_contour`, on prend en plus en argument le découpage en cellule de la plage de recherche, les coordonnées de la cellule dans lequel l'algorithme parent se trouve, ainsi que le bord de la cellule depuis lequel on souhaite initialiser l'algorithme.\n",
    "- Cet algorithme n'est qu'une adaptation de la méthode présentéee dans la partie précédente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_contour(g,xc,yc,nom_bord,i,j,c=0,delta=0.001):\n",
    "    abscisses , ordonnées = [],[]\n",
    "    dic_fonction = {\"UP\" : find_seed_U, \"LEFT\":find_seed_L, \"RIGHT\" : find_seed_R,\"DOWN\" : find_seed_D }\n",
    "    position = dic_fonction[nom_bord](g,c,[xc[i],xc[i+1]], [yc[j],yc[j+1]])\n",
    "    gradg=autograd.grad(g)\n",
    "    if  not isinstance( position,list) :\n",
    "        return [],[]\n",
    "    else:\n",
    "        position = np.array(position)        \n",
    "        abscisses.append(position[0])\n",
    "        ordonnées.append(position[1])\n",
    "        def test (position):\n",
    "            return xc[i]<=position[0]<=xc[i+1] and yc[j]<=position[1]<=yc[j+1]\n",
    "        while test(position) :\n",
    "            gradX=gradg(position)\n",
    "            norme = np.sqrt(gradX[1]**2+gradX[0]**2)\n",
    "            vect = np.array([gradX[1]/norme,-1*gradX[0]/norme])\n",
    "            position = position + vect*delta\n",
    "\n",
    "            abscisses.append(position[0])\n",
    "            ordonnées.append(position[1])\n",
    "        return abscisses,ordonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Découpe et compilation des fragments\n",
    "\n",
    "#Gaspard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_complexe(f, c=0, xc = [0,1], yc = [0,1], delta = 0.01):\n",
    "    xs,ys= [], []\n",
    "\n",
    "    liste_bord = ['UP','LEFT','RIGHT','DOWN']\n",
    "    for i in range(len(xc)-1):\n",
    "        for j in range(len(yc)-1):\n",
    "            for nom_bord in liste_bord :\n",
    "                X,Y=simple_contour(f,xc,yc,nom_bord,i,j,c,delta)\n",
    "                xs.append(X)\n",
    "                ys.append(Y)\n",
    "    return xs,ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracé\n",
    "\n",
    "#Gaspard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(g,xc,yc,c=0):\n",
    "    a,b=contour_complexe(g,c,xc,yc)\n",
    "    for x,y in zip(a,b):\n",
    "        plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in [0,1,0.5,1.5,-0.5,-1,-1.5]:\n",
    "    trace(f,np.linspace(-3,3,10),np.linspace(-3,3,10),i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des lignes de niveau en 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain_x=np.linspace(-3,3,100)\n",
    "domain_y=np.linspace(-3,3,100)\n",
    "X,Y=np.meshgrid(domain_x,domain_y)\n",
    "         \n",
    "Z=f([X,Y])\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "\n",
    "ax=Axes3D(fig)\n",
    "\n",
    "ax.plot_wireframe(X,Y,Z, label=\"plot\")\n",
    "def trace(g,xc,yc,c=0):\n",
    "    a,b=contour_complexe(f,c,np.linspace(-3,3,10),np.linspace(-3,3,10))\n",
    "    for x,y in zip(a,b):\n",
    "        ax.plot(x,y,c,'r',linewidth=6)\n",
    "        \n",
    "for i in [0,1,0.5,1.5,-0.5,-1,-1.5]:\n",
    "    trace(f,np.linspace(-3,3,10),np.linspace(-3,3,10),i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plus grande Précision\n",
    "\n",
    "- Comme présenté précedemment dans la premère technique l'erreur s'accumule et notre courbe de niveau dérive par rapport à la réalité. On va donc corriger chaque point obtenu par la première méthode en le remplaçant par un point réellement sur la courbe de niveau.\n",
    "- Ce point $ (x,y)$ doit vérifier $f(x,y)=c$, mais aussi appartenir au cercle de centre le point précédent $(x_i,y_i)$ et de rayon $\\delta$ ; c'est à dire vérifier  : $(x-x_i)^2+(y-y_i)^2-\\delta^2=0$\n",
    "- Déterminer ce nouveau point, c'est résoudre le système $H(x,y)=(0,0) où H(X)=\\begin{pmatrix} f(x,y)-c   \\\\(x-x_i)^2+(y-y_i)^2 \\end{pmatrix}$\n",
    "- On peut alors utiliser la méthode de Newton que l'on initialise en $(x_e,y_e)$, coordonnées du point  données par la méthode dite de la tangente. La formule de récurrence dans notre cadre devient $X_{k+1}=X_k-J_H(X_k)^{-1}.H(X_k)$. On aura vérifié au préalable que la matrice est bien inversible.\n",
    "- Encore une fois on arrête l'itération lorsque on a atteint une précision au moins égale à $\\epsilon = 2^{-26=}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_contour(g,xc,yc,nom_bord,i,j,c=0,delta=0.001,eps=2**(-26)):\n",
    "    abscisses , ordonnées = [],[]\n",
    "    dic_fonction = {\"UP\" : find_seed_U, \"LEFT\":find_seed_L, \"RIGHT\" : find_seed_R,\"DOWN\" : find_seed_D }\n",
    "    position = dic_fonction[nom_bord](g,c,[xc[i],xc[i+1]], [yc[j],yc[j+1]])\n",
    "    gradg=autograd.grad(g)\n",
    "    if  not isinstance( position,list) :\n",
    "        return [],[]\n",
    "    else:\n",
    "        position = np.array(position)     \n",
    "        abscisses.append(position[0])\n",
    "        ordonnées.append(position[1])\n",
    "\n",
    "        def test (position):\n",
    "            return xc[i]<=position[0]<=xc[i+1] and yc[j]<=position[1]<=yc[j+1]\n",
    "        while test(position) :\n",
    "            gradX=gradg(position)\n",
    "            norme = np.sqrt(gradX[1]**2+gradX[0]**2)\n",
    "            vect = np.array([gradX[1]/norme,-1*gradX[0]/norme])\n",
    "            position_faux = position + vect*delta\n",
    "            position1=position\n",
    "\n",
    "            def h1 (x,y):\n",
    "                return g(np.array([x,y]))-c\n",
    "            def h2 (x,y):\n",
    "                return (x - position1[0])**2 + (y - position1[1])**2 - delta**2\n",
    "            def H(x,y) : \n",
    "                return np.array([h1(x,y),h2(x,y)])\n",
    "            \n",
    "            def J_H(x,y):\n",
    "                \n",
    "                j = autograd.jacobian\n",
    "                return np.c_[j(H, 0)(x,y), j(H, 1)(x,y)]\n",
    "            \n",
    "            \n",
    "            J=J_H(position_faux[0],position_faux[1])\n",
    "            if np.linalg.det(J)==0:\n",
    "                abscisses.append(position_faux[0])\n",
    "                ordonnées.append(position_faux[1])\n",
    "            else:\n",
    "\n",
    "                J_inv=np.linalg.inv(J)\n",
    "                position=position_faux -J_inv@H(position_faux[0],position_faux[1])\n",
    "                while np.linalg.norm(position-position_faux)>eps:\n",
    "                    position_faux=position\n",
    "                    J=J_H(position_faux[0],position_faux[1])\n",
    "                    if np.linalg.det(J)==0:\n",
    "                        break\n",
    "                    else:\n",
    "                        J_inv=np.linalg.inv(J)\n",
    "                        position=position_faux -J_inv@H(position_faux[0],position_faux[1])\n",
    "                abscisses.append(position[0])\n",
    "                ordonnées.append(position[1])\n",
    "\n",
    "        return abscisses,ordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_complexe(f, c=0, xc = [0,1], yc = [0,1], delta = 0.01):\n",
    "    xs,ys= [], []\n",
    "\n",
    "    liste_bord = ['UP','LEFT','RIGHT','DOWN']\n",
    "    for i in range(len(xc)-1):\n",
    "        for j in range(len(yc)-1):\n",
    "            for nom_bord in liste_bord :\n",
    "                X,Y=simple_contour(f,xc,yc,nom_bord,i,j,c,delta)\n",
    "                xs.append(X)\n",
    "                ys.append(Y)\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(g,xc,yc,c=0):\n",
    "    a,b=contour_complexe(g,c,xc,yc)\n",
    "    for x,y in zip(a,b):\n",
    "        plt.plot(x,y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in [0,1,0.5,1.5,-0.5,-1,-1.5]:\n",
    "    trace(f,np.linspace(-3,3,10),np.linspace(-3,3,10),i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erreur\n",
    "#Gaspard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=simple_contour(g,[0,1],[0,1],'LEFT',0,0,1,0.5)\n",
    "b=simple_contour(g,[0,1],[0,1],'LEFT',0,0,1,0.1)\n",
    "c=simple_contour(g,[0,1],[0,1],'LEFT',0,0,1,0.01)\n",
    "plt.close()\n",
    "plt.figure(figsize=(10,5))\n",
    "print(a[0],a[1])\n",
    "plt.subplot(121)\n",
    "plt.title(\" Tracé de la ligne de niveau en fonction de $\\delta$\")\n",
    "plt.plot(a[0],a[1],label='$\\delta$=0.5')\n",
    "plt.plot(b[0],b[1],label='$\\delta$=0.1')\n",
    "plt.plot(c[0],c[1],label='$\\delta$=0.01')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(abs((np.array(a[0])**2+np.array(a[1])**2)-1),label='$\\delta$=0.5')\n",
    "#plt.plot(abs((np.array(b[0])**2+np.array(b[1])**2)-1),label='$\\delta$=0.1')\n",
    "#plt.plot(abs((np.array(c[0])**2+np.array(c[1])**2)-1),label='$\\delta$=0.01')\n",
    "plt.title(\"Tracé de l'erreur en fonction du nombre d'itération\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
